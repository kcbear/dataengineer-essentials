# dataengineer-essentials


Data Engineer
Sydney, Australia
9-12 months initially
$1,000 per day (inclusive of super)

Join our leading Australian Insurance Business in Sydney as a Data Engineer migrating from on-prem systems to Azure Cloud which will require expertise in Databricks.

Responsibilities:
* Collaborate with cross-functional teams to develop migration strategies and implement robust solutions.
* Design and develop data pipelines, ETL processes, and workflows using Databricks.
* Optimize data models and database performance for efficient data retrieval and storage.
* Implement data quality controls, governance frameworks, and ensure data integrity and security.
* Analyze business requirements and provide technical recommendations.
* Troubleshoot and resolve data-related issues with minimal disruption.

Requirements:
* Proven experience as a Data Engineer with Azure and Databricks expertise.
* Strong SQL, Python, and scripting skills for data manipulation.
* Experience in data modeling, warehousing, and ETL processes.
* Familiarity with data governance, quality, and security principles.
* Excellent communication and problem-solving skills.
* Join us on our transformative cloud migration journey, working with cutting-edge technologies. Make an impact and drive innovation in our organization.



--
Lead Data Engineer

Sydney, Australia

$200,000 (inc super) + Benefits

Leading bank in Australia are seeking a skilled Lead Data Engineer to join their team in Sydney. As the Lead Data Engineer, you will drive the delivery of the data engineering capability, leading a team of Data Engineers to deliver high-quality and cost-effective solutions.


Responsibilities:

Lead and mentor a team of Data Engineers
Design, develop, and support data engineering projects
Improve data acquisition, modeling, and processes
Drive agile delivery and automation
Engage and manage stakeholders effectively
Requirements:

10+ years of experience in technical roles
3+ years of experience as a Lead Data Engineer
5+ years of program development experience in data functions
Strong involvement in major data transformation initiatives
Experience with data lakes, warehouses, Databricks, and data streaming
Proficiency in AWS, SAS, SQL, Python, PowerBI, etc.
